{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar - JSON, XML, Requests, Web-Scraping \n",
    "by Vítek Macháček\n",
    "\n",
    "## Task 1: JSON API and Quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Quandl access credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "QUANDL_API_KEY = 'jsVA9hLwyzY_Pg21uzR4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request Quandl for time series:\n",
    "\n",
    "hint: The most simple Quandl Format for API-call is:\n",
    "\n",
    "https://www.quandl.com/api/v3/datasets/{QUANDL_DATABASE}/{QUANDL_DATASET}/data.{DATA_FORMAT}?api_key={YOUR-QUANDL-API-KEY}\n",
    "\n",
    "QUANDL_API_KEY='jsVA9hLwyzY_Pg21uzR4'Let's ask for `FB` dataset from `WIKI` database. The results should be in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FB'\n",
    "database = 'WIKI'\n",
    "form = 'json'\n",
    "url = f'https://www.quandl.com/api/v3/datasets/{database}/{dataset}/data.{form}?api_key={QUANDL_API_KEY}'#.format(database,dataset,'json',QUANDL_API_KEY)\n",
    "\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert response to python natives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What keys does a dictionary contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset_data'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['dataset_data'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Volume',\n",
       " 'Ex-Dividend',\n",
       " 'Split Ratio',\n",
       " 'Adj. Open',\n",
       " 'Adj. High',\n",
       " 'Adj. Low',\n",
       " 'Adj. Close',\n",
       " 'Adj. Volume']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['dataset_data']['column_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first data point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-03-27',\n",
       " 156.31,\n",
       " 162.85,\n",
       " 150.75,\n",
       " 152.19,\n",
       " 76787884.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 156.31,\n",
       " 162.85,\n",
       " 150.75,\n",
       " 152.19,\n",
       " 76787884.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['dataset_data']['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>156.31</td>\n",
       "      <td>162.85</td>\n",
       "      <td>150.75</td>\n",
       "      <td>152.1900</td>\n",
       "      <td>76787884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.31</td>\n",
       "      <td>162.85</td>\n",
       "      <td>150.75</td>\n",
       "      <td>152.1900</td>\n",
       "      <td>76787884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>160.82</td>\n",
       "      <td>161.10</td>\n",
       "      <td>149.02</td>\n",
       "      <td>160.0600</td>\n",
       "      <td>125438294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.82</td>\n",
       "      <td>161.10</td>\n",
       "      <td>149.02</td>\n",
       "      <td>160.0600</td>\n",
       "      <td>125438294.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>165.44</td>\n",
       "      <td>167.10</td>\n",
       "      <td>159.02</td>\n",
       "      <td>159.3900</td>\n",
       "      <td>52306891.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.44</td>\n",
       "      <td>167.10</td>\n",
       "      <td>159.02</td>\n",
       "      <td>159.3900</td>\n",
       "      <td>52306891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>166.13</td>\n",
       "      <td>170.27</td>\n",
       "      <td>163.72</td>\n",
       "      <td>164.8900</td>\n",
       "      <td>73389988.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.13</td>\n",
       "      <td>170.27</td>\n",
       "      <td>163.72</td>\n",
       "      <td>164.8900</td>\n",
       "      <td>73389988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>164.80</td>\n",
       "      <td>173.40</td>\n",
       "      <td>163.30</td>\n",
       "      <td>169.3900</td>\n",
       "      <td>105350867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.80</td>\n",
       "      <td>173.40</td>\n",
       "      <td>163.30</td>\n",
       "      <td>169.3900</td>\n",
       "      <td>105350867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>2012-05-24</td>\n",
       "      <td>32.95</td>\n",
       "      <td>33.21</td>\n",
       "      <td>31.77</td>\n",
       "      <td>33.0300</td>\n",
       "      <td>50237200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.95</td>\n",
       "      <td>33.21</td>\n",
       "      <td>31.77</td>\n",
       "      <td>33.0300</td>\n",
       "      <td>50237200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>2012-05-23</td>\n",
       "      <td>31.37</td>\n",
       "      <td>32.50</td>\n",
       "      <td>31.36</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>73600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.37</td>\n",
       "      <td>32.50</td>\n",
       "      <td>31.36</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>73600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>2012-05-22</td>\n",
       "      <td>32.61</td>\n",
       "      <td>33.59</td>\n",
       "      <td>30.94</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>101786600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.61</td>\n",
       "      <td>33.59</td>\n",
       "      <td>30.94</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>101786600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2012-05-21</td>\n",
       "      <td>36.53</td>\n",
       "      <td>36.66</td>\n",
       "      <td>33.00</td>\n",
       "      <td>34.0300</td>\n",
       "      <td>168192700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.53</td>\n",
       "      <td>36.66</td>\n",
       "      <td>33.00</td>\n",
       "      <td>34.0300</td>\n",
       "      <td>168192700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>2012-05-18</td>\n",
       "      <td>42.05</td>\n",
       "      <td>45.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>38.2318</td>\n",
       "      <td>573576400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.05</td>\n",
       "      <td>45.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>38.2318</td>\n",
       "      <td>573576400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low     Close       Volume  Ex-Dividend  \\\n",
       "0     2018-03-27  156.31  162.85  150.75  152.1900   76787884.0          0.0   \n",
       "1     2018-03-26  160.82  161.10  149.02  160.0600  125438294.0          0.0   \n",
       "2     2018-03-23  165.44  167.10  159.02  159.3900   52306891.0          0.0   \n",
       "3     2018-03-22  166.13  170.27  163.72  164.8900   73389988.0          0.0   \n",
       "4     2018-03-21  164.80  173.40  163.30  169.3900  105350867.0          0.0   \n",
       "...          ...     ...     ...     ...       ...          ...          ...   \n",
       "1467  2012-05-24   32.95   33.21   31.77   33.0300   50237200.0          0.0   \n",
       "1468  2012-05-23   31.37   32.50   31.36   32.0000   73600000.0          0.0   \n",
       "1469  2012-05-22   32.61   33.59   30.94   31.0000  101786600.0          0.0   \n",
       "1470  2012-05-21   36.53   36.66   33.00   34.0300  168192700.0          0.0   \n",
       "1471  2012-05-18   42.05   45.00   38.00   38.2318  573576400.0          0.0   \n",
       "\n",
       "      Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume  \n",
       "0             1.0     156.31     162.85    150.75    152.1900   76787884.0  \n",
       "1             1.0     160.82     161.10    149.02    160.0600  125438294.0  \n",
       "2             1.0     165.44     167.10    159.02    159.3900   52306891.0  \n",
       "3             1.0     166.13     170.27    163.72    164.8900   73389988.0  \n",
       "4             1.0     164.80     173.40    163.30    169.3900  105350867.0  \n",
       "...           ...        ...        ...       ...         ...          ...  \n",
       "1467          1.0      32.95      33.21     31.77     33.0300   50237200.0  \n",
       "1468          1.0      31.37      32.50     31.36     32.0000   73600000.0  \n",
       "1469          1.0      32.61      33.59     30.94     31.0000  101786600.0  \n",
       "1470          1.0      36.53      36.66     33.00     34.0300  168192700.0  \n",
       "1471          1.0      42.05      45.00     38.00     38.2318  573576400.0  \n",
       "\n",
       "[1472 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d['dataset_data']['data'],columns=d['dataset_data']['column_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps column names can be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b: XML (not covered on seminar)\n",
    "Request XML format of the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let just save a XML into a file `xml_sample.xml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get BeatifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK gimme a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Quandl website\n",
    "\n",
    "Let's get a list of available datasets on Quandl:\n",
    "\n",
    "The list of datasets on Quandl website is available at: https://www.quandl.com/search?filters=%5B%22Free%22%5D\n",
    "\n",
    "Is this website scrapable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Scraping IES news\n",
    "\n",
    "use following code snippets to construct your own IES News web scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(link):\n",
    "    '''\n",
    "    Function accepts a link and returns a BeautifulSoup object parsed from text of a succesful GET request on a link. If requests returns other status code than 200, returns None and prints a message\n",
    "\n",
    "    Make sure that the request object is parsed as UTF-8 string.\n",
    "    '''\n",
    "    r = requests.get(link)\n",
    "    r.encoding = 'utf-8'\n",
    "    if r.status_code == 200:\n",
    "        return BeautifulSoup(r.text)\n",
    "    else:\n",
    "        print('Request on URL {} failed with status code {}'.format(link,r.status_code))\n",
    "\n",
    "soup = get_soup('https://ies.fsv.cuni.cz/content/tree/index/lang/en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news_links(link):\n",
    "    '''\n",
    "    Generates list of URLs of all news-related links from the url provided.\n",
    "\n",
    "    Links on news format: <a href=\"/en/news/{id}\" title=\"show news\" class=\"show-news\">show news</a>\n",
    "\n",
    "    The URLs are expected in absolute format, i.e. including a full domain.\n",
    "    '''\n",
    "    \n",
    "    soup = get_soup(link)\n",
    "    \n",
    "    return ['https://ies.fsv.cuni.cz' + a['href'] for a in soup.find_all('a',{'class':'show-news'})]\n",
    "links = get_all_news_links('https://ies.fsv.cuni.cz/content/tree/index/lang/en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup(links[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rejustify: a new AI-enhanced database available to our students'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_title(soup):\n",
    "    '''\n",
    "    Parse text of the first `h3` object from the soup element.\n",
    "    '''\n",
    "    return soup.find('h3').text\n",
    "parse_title(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-11 00:00:00')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_date(soup):\n",
    "    '''\n",
    "    Parse text of the sibling of sibling of the first h3 element in the soup. Note that the immidiate sibling of `h3` is not Tag element, but NavigableString. This is used to represent text between tags.\n",
    "    '''\n",
    "\n",
    "    return soup.find('h3').next_sibling.next_sibling.text\n",
    "pd.Timestamp(parse_date(soup),format='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/11/2020\n",
      " \n",
      " \n",
      "Rejustify is an AI-enhanced ETL tool (Extract-Transform-Load) for data set preparation and merging data from multiple sources. The rejustify's algorithm analyzes an empty dataset to recognize its structure and suggests source tables from primary sources of data that match the best. Followed by a \"fill\" function which sends data queries to the primary sources and fills the required data into the dataset.\n",
      " \n",
      " \n",
      "Rejustify has automatized merging and combining data from more than 600 million data series from over 60 most trusted statistical sources like Eurostat, ECB, UN, IMF, statistical offices and central banks, including additional sources like CO2 emissions, Cryptocurrency prices, or COVID-19 cases.\n",
      " \n",
      " \n",
      "Rejustify is an online service available through Google Sheets, R and Python. Registration and instruction videos are at rejustify.com and you can contact info@rejustify.com in case of any questions, suggestions and comments.\n",
      " \n",
      " \n",
      "Each semester, first 100 students and staff of IES can claim their free access to premium account with Jiri Kukacka.\n",
      " \n",
      " \n",
      "Autor - PhDr. Jiří Kukačka Ph.D.\n"
     ]
    }
   ],
   "source": [
    "def parse_news_content(soup):\n",
    "    '''\n",
    "    For simplicity, the content of the article is the content of all <p> elements within <div class=\"col-sm-12 news\"></div>\n",
    "\n",
    "    Return a single string with the whole text. Use `/n` as a connecting string between individual p-texts. \n",
    "\n",
    "    Hint: Consider using a `.join()` function applicable on string object\n",
    "    '''\n",
    "    div = soup.find('div',{'class':'col-sm-12 news'})\n",
    "    return '\\n \\n \\n'.join([p.text for p in div.find_all('p')])\n",
    "print(parse_news_content(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       Pre-Defense of Adam Kučera's dissertation thesis\n",
       "date                                              09/11/2020\n",
       "content    09/11/2020\\n \\n \\nThe pre-defense of Adam Kuče...\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_ies_news(link,pause=.5):\n",
    "    '''\n",
    "    From URL of given news story generate pd.Series object with `title`, `date` and `content`.\n",
    "\n",
    "    Use functions `parse_title`, `parse_date` and `parse_news_content` to get individual attributes.\n",
    "\n",
    "    Please, keep the sleep() to prevent overflow of IES website.\n",
    "    '''\n",
    "\n",
    "    time.sleep(pause)\n",
    "    \n",
    "    soup = get_soup(link)\n",
    "    return pd.Series({\n",
    "        'title':parse_title(soup),\n",
    "        'date':parse_date(soup),\n",
    "        'content':parse_news_content(soup),\n",
    "    })\n",
    "parse_ies_news(links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_news(link):\n",
    "    '''\n",
    "    wraping fuctions that accepts a `link` pointing towards hub website with links to parse and returing a dataframe containing all the links\n",
    "    '''\n",
    "    links = get_all_news_links(link)\n",
    "    \n",
    "    return pd.DataFrame([parse_ies_news(link) for link in links])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pre-Defense of Adam Kučera's dissertation thesis</td>\n",
       "      <td>09/11/2020</td>\n",
       "      <td>09/11/2020\\n \\n \\nThe pre-defense of Adam Kuče...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job offer at Deloitte</td>\n",
       "      <td>09/11/2020</td>\n",
       "      <td>09/11/2020\\n \\n \\nTeam Valuation &amp; Financial M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>European Business Forum online and free of cha...</td>\n",
       "      <td>06/11/2020</td>\n",
       "      <td>06/11/2020\\n \\n \\nEuropean Business Forum, Dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alumna of the Month in October: Y My Černá Vu</td>\n",
       "      <td>05/11/2020</td>\n",
       "      <td>05/11/2020\\n \\n \\n\\n \\n \\nIn October, we choos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Global Universities: Charles University h...</td>\n",
       "      <td>03/11/2020</td>\n",
       "      <td>03/11/2020\\n \\n \\nFor the seventh year already...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        date  \\\n",
       "0   Pre-Defense of Adam Kučera's dissertation thesis  09/11/2020   \n",
       "1                              Job offer at Deloitte  09/11/2020   \n",
       "2  European Business Forum online and free of cha...  06/11/2020   \n",
       "3      Alumna of the Month in October: Y My Černá Vu  05/11/2020   \n",
       "4  Best Global Universities: Charles University h...  03/11/2020   \n",
       "\n",
       "                                             content  \n",
       "0  09/11/2020\\n \\n \\nThe pre-defense of Adam Kuče...  \n",
       "1  09/11/2020\\n \\n \\nTeam Valuation & Financial M...  \n",
       "2  06/11/2020\\n \\n \\nEuropean Business Forum, Dan...  \n",
       "3  05/11/2020\\n \\n \\n\\n \\n \\nIn October, we choos...  \n",
       "4  03/11/2020\\n \\n \\nFor the seventh year already...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = get_all_news('https://ies.fsv.cuni.cz/content/tree/index/lang/en')\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Convert Task 3 into OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class News:\n",
    "    def __init__(self,link):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Downloader:\n",
    "    def __init__(self,hub_url):\n",
    "        pass\n",
    "\n",
    "\n",
    "dl = Downloader('https://ies.fsv.cuni.cz/content/tree/index/lang/en')\n",
    "dl.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
